{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('textattack/bert-base-uncased-MRPC')\n",
    "model_my = AutoModelForSequenceClassification.from_pretrained('textattack/bert-base-uncased-MRPC')\n",
    "\n",
    "dataset = load_dataset('glue', 'mrpc')"
   ],
   "id": "87afe6e0f93a278f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(model_my)\n",
    "print(dataset)\n",
    "print(dataset['train']['sentence1'][0])\n",
    "print(dataset['train']['sentence2'][0])\n",
    "print(dataset['train']['label'][0])"
   ],
   "id": "257b07da8a69d84d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def tokenize_function(text):\n",
    "    return tokenizer(text[\"sentence1\"], text[\"sentence2\"], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ],
   "id": "685c5fe44a8401ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def draw(weights, name, mask):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bin_width = 0.005\n",
    "    bins = np.arange(-0.6, 0.6, bin_width)\n",
    "    plt.hist(weights.view(-1).cpu(), bins=bins, alpha=0.75, color='blue', edgecolor='black')\n",
    "    plt.hist(weights[mask[name + '.weight'] > 0].view(-1).cpu(), bins=bins, alpha=0.75, color='red', edgecolor='black')\n",
    "    plt.title(name)\n",
    "    plt.xlim([-0.6, 0.6])\n",
    "    plt.ylim([0, 100])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    # plt.savefig(f\"imgs/{name}.png\")\n",
    "    # plt.close()\n",
    "    return"
   ],
   "id": "9558143d56beaed1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tokenized_dataset = tokenized_dataset.remove_columns(['sentence1', 'sentence2', 'idx'])\n",
    "tokenized_dataset = tokenized_dataset.rename_column('label', 'labels')\n",
    "tokenized_dataset.set_format('pt')"
   ],
   "id": "cc6abd1c75eb2cd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(tokenized_dataset)\n",
    "print(tokenized_dataset['train']['labels'][0])\n",
    "print(tokenized_dataset['train']['input_ids'][0])\n",
    "print(tokenized_dataset['train']['token_type_ids'][0])\n",
    "print(tokenized_dataset['train']['attention_mask'][0])"
   ],
   "id": "91c76df23bdd20f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ori_dict = {}\n",
    "ori_max = {}\n",
    "ori_min = {}\n",
    "for name, module in model_my.named_modules():\n",
    "    if 'query' in name or 'key' in name or 'value' in name:\n",
    "        name = name + '.weight'\n",
    "        ori_dict[name] = module.weight\n",
    "        flattened_para = module.weight.view(-1)\n",
    "        # ori_dict[name] = flattened_para\n",
    "        sorted_tensor, _ = torch.sort(flattened_para)\n",
    "        num_elements = flattened_para.numel()\n",
    "        top_1_percent_idx = num_elements - 50\n",
    "        bottom_1_percent_idx = 50\n",
    "        top_1_percent_value = sorted_tensor[top_1_percent_idx].item()\n",
    "        bottom_1_percent_value = sorted_tensor[bottom_1_percent_idx].item()\n",
    "        ori_max[name] = top_1_percent_value\n",
    "        ori_min[name] = bottom_1_percent_value"
   ],
   "id": "bc3e44f1874021b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataloader = DataLoader(tokenized_dataset['train'], batch_size=1, shuffle=False)\n",
    "eval_dataloader = DataLoader(tokenized_dataset['validation'], batch_size=1, shuffle=False)\n",
    "device = 'cuda'\n",
    "\n",
    "model_my = model_my.to(device)\n",
    "model_my.train()\n",
    "model_my.zero_grad()\n",
    "\n",
    "for data in train_dataloader:\n",
    "    #print(data)\n",
    "    data = {k: v.to(device) for k, v in data.items()}\n",
    "    outputs = model_my(**data)\n",
    "    # print(model.bert.encoder.layer[-1].attention.self.query.weight.grad)\n",
    "    print(outputs.loss)\n",
    "    outputs.loss.backward()\n",
    "    # print(model.bert.encoder.layer[-1].attention.self.query.weight.grad)\n",
    "    print(torch.argmax(outputs.logits.flatten())==data['labels'][0])\n",
    "\n",
    "    break"
   ],
   "id": "cabe9c4d351c9812",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for name, module in model.named_modules():\n",
    "#     if 'query' in name or 'key' in name or 'value' in name:\n",
    "#         print(name)\n",
    "#         print(module.weight.numel())\n",
    "mask = {}\n",
    "idx_list = []\n",
    "ori_w = []\n",
    "ratio = 0.0001\n",
    "for name, module in model_my.named_modules():\n",
    "    if 'query' in name or 'key' in name or 'value' in name:\n",
    "        weight_name = name + '.weight'\n",
    "        weights = module.weight.data\n",
    "        \n",
    "        # 展平权重\n",
    "        flattened_weights = weights.view(-1)\n",
    "        replace_count = int(ratio * len(flattened_weights))\n",
    "        replace_count = max(0, replace_count)\n",
    "        # print(replace_count)\n",
    "        mask[weight_name] = torch.zeros_like(flattened_weights)\n",
    "        \n",
    "        if module.weight.grad is None:\n",
    "            raise ValueError(f\"{name}\")\n",
    "        grad_abs = module.weight.grad.detach().abs()\n",
    "        _, topk_idx = grad_abs.view(-1).topk(replace_count)\n",
    "        mask[weight_name][topk_idx] = 1\n",
    "        \n",
    "        mask[weight_name] = mask[weight_name].view(weights.size())\n",
    "        \n",
    "        indexes = torch.nonzero(mask[weight_name], as_tuple=True)\n",
    "        idx_list.append(indexes)\n",
    "        selected_weights = weights[indexes]\n",
    "        ori_w.extend(selected_weights.cpu().detach().numpy().flatten())\n",
    "\n",
    "print(\"mask include:\", mask.keys())"
   ],
   "id": "87c2ebba6e6256d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for name, module in model_my.named_modules():\n",
    "    name = name + '.weight'\n",
    "    if name in mask:\n",
    "        print(mask[name])\n",
    "        print(module.weight.grad.detach().abs()[mask[name]])\n",
    "        break"
   ],
   "id": "43cc7238e8e24e12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('textattack/bert-base-uncased-MRPC')\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=0.0005, eps=1e-8)\n",
    "\n",
    "\n",
    "for epoch in range(5):  # Specify how many epochs to cycle through the training\n",
    "    # set to the eval mode to fix the paramaters of batchnorm\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    progress_bar = tqdm(eval_dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        \n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        kld = 0\n",
    "        cnt = 0\n",
    "        total_cnt = 0\n",
    "        for name, para in model.named_parameters():\n",
    "            if name in mask:\n",
    "                flattened_para = para[mask[name] > 0].view(-1)\n",
    "                flattened_ori = ori_dict[name].to(device)[mask[name] > 0].view(-1)\n",
    "                flattened_para = flattened_para[torch.argsort(flattened_para)]\n",
    "                flattened_ori = flattened_ori[torch.argsort(flattened_ori)]\n",
    "                cnt += 1\n",
    "                if flattened_para.numel() != 0:\n",
    "                    kl_t1 = torch.log_softmax(flattened_para, dim=0)\n",
    "                    kl_t2 = torch.softmax(flattened_ori + 1e-10, dim=0)\n",
    "                    kld_tmp = torch.nn.functional.kl_div(kl_t1, kl_t2, reduction='sum')\n",
    "                    if kld_tmp.item() > 0.0:\n",
    "                        kld += kld_tmp.item()\n",
    "        loss_new = -loss + 2 ** (kld * 5e1)\n",
    "        total_loss += loss_new.item()\n",
    "        \n",
    "  \n",
    "        loss_new.backward()\n",
    "        for name, para in model.named_parameters():\n",
    "            if name in mask:\n",
    "                para.grad *= mask[name].long()\n",
    "            else:\n",
    "                para.grad *= 0\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            for name, para in model.named_parameters():\n",
    "                if name in mask:\n",
    "                    # param.clamp_(-arg.clip, arg.clip)\n",
    "                    para.data = (1 - mask[name]) * para + (mask[name] * para).clamp_(ori_min[name] * 0.85,\n",
    "                                                                                         ori_max[name] * 0.75)\n",
    "\n",
    "        progress_bar.set_postfix({'loss': loss.item(),'loss_new': loss_new.item(),'kld': 2 ** (kld * 5e1)})\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "            data = {k: v.to(device) for k, v in data.items()}\n",
    "            outputs = model(**data)\n",
    "            \n",
    "            predictions = torch.argmax(outputs.logits, dim=1)\n",
    "            correct = (predictions == data['labels']).sum().item()\n",
    "            \n",
    "            total_correct += correct\n",
    "            total_samples += data['labels'].size(0)\n",
    "    \n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    changed = 0\n",
    "    uncut = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if (name + '.weight') in mask:\n",
    "            changed += (mask[name + '.weight'] > 0).sum()\n",
    "            uncut += ((module.weight.data[mask[name + '.weight'] > 0] >= ori_min[name+ '.weight'] * 0.85) & (module.weight.data[mask[name + '.weight'] > 0] <= ori_max[name+ '.weight'] * 0.75)).sum().item()\n",
    "        if 'value' in name:\n",
    "            if 'layer.6' in name:\n",
    "                draw(module.weight.data, name, mask)\n",
    "                # draw(ori_dict[name + '.weight'].data, name, mask)\n",
    "                name = name + '.weight'\n",
    "                flattened_weights = module.weight.data.cpu().numpy().flatten()\n",
    "                flattened_ori = ori_dict[name].data.cpu().numpy().flatten()\n",
    "                weight_diff = flattened_weights - flattened_ori\n",
    "                changed_indices = np.where(np.abs(weight_diff) > 1e-5)\n",
    "                print(len(changed_indices[0]))\n",
    "    # \n",
    "    print(uncut)\n",
    "    print(f'{changed} weights changed')\n",
    "    if accuracy > 0.7:\n",
    "        continue\n",
    "    step = 0.1\n",
    "    with torch.no_grad():\n",
    "        for name, module in model.named_modules():\n",
    "            name = name + '.weight'\n",
    "            if 'query' in name or 'key' in name or 'value' in name:\n",
    "                weights = module.weight.data\n",
    "                # flattened_weights = weights.view(-1)\n",
    "                replace_count = int(step * mask[name].sum())\n",
    "                # print((module.weight.grad.detach().abs() * mask[name]).view(-1).shape)\n",
    "                if replace_count == 0:\n",
    "                    replace_count = 1\n",
    "                temp_weight = module.weight.grad.detach().abs() * mask[name]\n",
    "                temp_weight += 1 - mask[name]\n",
    "                temp_weight = temp_weight.view(-1)\n",
    "                _, w_idx_mink = temp_weight.topk(replace_count, largest=False)\n",
    "                zero_mask = torch.zeros_like(temp_weight)\n",
    "                zero_mask[w_idx_mink] = 1\n",
    "                # if 'layer2.1.conv1' in name or 'features.4' in name:\n",
    "                #     print((weights[mask[name] > 0]).numel())\n",
    "                #     print((weights.view(-1) != ori_dict[name].view(-1)).sum().item())\n",
    "                    # print(weights[mask[name] > 0])\n",
    "                    # print(ori_dict[name][mask[name] > 0])\n",
    "                    # mask_temp = mask[name].clone()\n",
    "                mask[name][zero_mask.view(mask[name].size()) > 0] = 0\n",
    "                weights[zero_mask.view(mask[name].size()) > 0] = ori_dict[name][zero_mask.view(mask[name].size()) > 0]\n",
    "                # if 'layer2.1.conv1' in name:\n",
    "                    # print(weights[mask_temp > 0])\n",
    "                    # print(ori_dict[name][mask_temp > 0])\n",
    "                    # print((weights[mask[name] > 0]).numel())\n",
    "                    # print((weights.view(-1) != ori_dict[name].view(-1)).sum().item())\n",
    "    optimizer = AdamW(model.parameters(), lr=0.0005, eps=1e-8)\n"
   ],
   "id": "290cd5df51ec1a5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# device = 'cuda'\n",
    "# model = model.to(device)\n",
    "# model.eval()\n",
    "# total_correct = 0\n",
    "# total_samples = 0\n",
    "# \n",
    "# with torch.no_grad():\n",
    "#     for data in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "#         data = {k: v.to(device) for k, v in data.items()}\n",
    "#         outputs = model(**data)\n",
    "#         \n",
    "#         predictions = torch.argmax(outputs.logits, dim=1)\n",
    "#         correct = (predictions == data['labels']).sum().item()\n",
    "#         \n",
    "#         total_correct += correct\n",
    "#         total_samples += data['labels'].size(0)\n",
    "# \n",
    "# accuracy = total_correct / total_samples\n",
    "# print(f\"Evaluation Accuracy: {accuracy:.4f}\")"
   ],
   "id": "df61f81a4fbd84ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if 'query' in name or 'key' in name or 'value' in name:\n",
    "        if 'layer.0' in name:\n",
    "            draw(module.weight.data, name, mask)\n",
    "            # draw(ori_dict[name + '.weight'].data, name, mask)\n",
    "            name = name + '.weight'\n",
    "            flattened_weights = module.weight.data.cpu().numpy().flatten()\n",
    "            flattened_ori = ori_dict[name].data.cpu().numpy().flatten()\n",
    "            weight_diff = flattened_weights - flattened_ori\n",
    "            changed_indices = np.where(np.abs(weight_diff) > 1e-5)\n",
    "            print(len(changed_indices[0]))\n",
    "            print(ori_max[name])\n",
    "            print(ori_min[name])"
   ],
   "id": "9a7e3da2e1f25416",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f'paras :{sum(p.numel() for p in model_my.parameters())}')",
   "id": "7461eb3e434e9347",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c00ffafc0e3cae89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "def plot_weight_comparison_gpu(model, ori_dict, name):\n",
    "    device = next(model.parameters()).device\n",
    "    weights_post = model.state_dict()[name].detach()\n",
    "    weights_pre = ori_dict[name].detach().to(device)\n",
    "    \n",
    "    def gpu_hist(tensor, bins):\n",
    "        counts = torch.histc(tensor, bins=len(bins)-1, min=bins[0], max=bins[-1])\n",
    "        return counts.cpu().numpy(), bins\n",
    "    \n",
    "    bin_edges_gpu = torch.linspace(-0.3, 0.3, steps=121, device=device)\n",
    "    bin_edges = bin_edges_gpu.cpu().numpy()\n",
    "    bin_width = bin_edges[1] - bin_edges[0]\n",
    "    \n",
    "    pre_freq, _ = gpu_hist(weights_pre, bin_edges_gpu)\n",
    "    post_freq, _ = gpu_hist(weights_post, bin_edges_gpu)\n",
    "    \n",
    "    lim = max(int(max(pre_freq.max(), post_freq.max()) * 1.2), 100)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.bar(bin_edges[:-1], pre_freq, width=bin_width, align='edge',\n",
    "            alpha=0.5, color='royalblue', edgecolor='none', label='Original Weights')\n",
    "    \n",
    "    plt.bar(bin_edges[:-1], -post_freq, width=bin_width, align='edge',\n",
    "            alpha=0.5, color='coral', edgecolor='none', label='Current Weights')\n",
    "    \n",
    "    diff = torch.abs(weights_post - weights_pre)\n",
    "    significant = diff > 1e-10  \n",
    "    if significant.any():\n",
    "        sig_pre = weights_pre[significant]\n",
    "        sig_post = weights_post[significant]\n",
    "        sig_pre_freq, _ = gpu_hist(sig_pre, bin_edges_gpu)\n",
    "        sig_post_freq, _ = gpu_hist(sig_post, bin_edges_gpu)\n",
    "        \n",
    "        plt.bar(bin_edges[:-1], sig_pre_freq, width=bin_width, align='edge',\n",
    "                alpha=0.8, color='blue', edgecolor='none', label='Significant Change (Orig)')\n",
    "        plt.bar(bin_edges[:-1], -sig_post_freq, width=bin_width, align='edge',\n",
    "                alpha=0.8, color='red', edgecolor='none', label='Significant Change (Current)')\n",
    "    \n",
    "    plt.xlim(-0.3, 0.3)\n",
    "    lim = 20\n",
    "    plt.ylim(-lim, lim)\n",
    "    plt.grid(True, which='both', linestyle=':', alpha=0.5)\n",
    "    plt.axhline(0, color='k', linewidth=1)\n",
    "    plt.title(f'Weight Distribution Comparison: {name}', fontsize=14)\n",
    "    plt.xlabel('Weight Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{abs(x):.0f}'))\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_combined_weights_gpu(model, ori_dict):\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    all_weights_pre = torch.tensor([], device=device)\n",
    "    all_weights_post = torch.tensor([], device=device)\n",
    "    all_diffs = torch.tensor([], device=device)\n",
    "    \n",
    "    for name, param in model.state_dict().items():\n",
    "        if ('query' in name or 'key' in name or 'value' in name) and 'weight' in name:\n",
    "            weights_post = param.detach().flatten()\n",
    "            weights_pre = ori_dict[name].detach().to(device).flatten()\n",
    "            diff = torch.abs(weights_post - weights_pre)\n",
    "            \n",
    "            all_weights_pre = torch.cat([all_weights_pre, weights_pre])\n",
    "            all_weights_post = torch.cat([all_weights_post, weights_post])\n",
    "            all_diffs = torch.cat([all_diffs, diff])\n",
    "    \n",
    "    bin_edges_gpu = torch.linspace(-0.5, 0.5, steps=121, device=device)\n",
    "    \n",
    "    def gpu_hist(tensor):\n",
    "        return torch.histc(tensor, bins=120, min=-0.5, max=0.5).cpu().numpy()\n",
    "    \n",
    "    pre_freq = gpu_hist(all_weights_pre)\n",
    "    post_freq = gpu_hist(all_weights_post)\n",
    "    \n",
    "    diff = torch.abs(all_weights_post - all_weights_pre)\n",
    "    significant = diff > 1e-10\n",
    "    sig_pre_freq = gpu_hist(all_weights_pre[significant])\n",
    "    sig_post_freq = gpu_hist(all_weights_post[significant])\n",
    "    \n",
    "    bin_edges = bin_edges_gpu.cpu().numpy()\n",
    "    bin_width = bin_edges[1] - bin_edges[0]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.bar(bin_edges[:-1], pre_freq, width=bin_width, align='edge',\n",
    "            alpha=0.3, color='lightblue', edgecolor='black', \n",
    "            label='Baseline')\n",
    "    plt.bar(bin_edges[:-1], -post_freq, width=bin_width, align='edge',\n",
    "            alpha=0.2, color='red', edgecolor='black',\n",
    "            label='DistShield')\n",
    "    \n",
    "    plt.bar(bin_edges[:-1], sig_pre_freq, width=bin_width, align='edge',\n",
    "            alpha=0.6, color='blue', edgecolor='black',\n",
    "            label='Before')\n",
    "    plt.bar(bin_edges[:-1], -sig_post_freq, width=bin_width, align='edge',\n",
    "            alpha=0.6, color='red', edgecolor='black',\n",
    "            label='After')\n",
    "    \n",
    "    max_freq = max(pre_freq.max(), post_freq.max())\n",
    "    plt.xlim(-0.5, 0.5)\n",
    "    lim = 300\n",
    "    plt.ylim(-lim, lim)\n",
    "    plt.grid(True, which='both', linestyle=':', alpha=0.5)\n",
    "    plt.axhline(0, color='k', linewidth=1)\n",
    "    \n",
    "    total_params = len(all_weights_pre)\n",
    "    changed_params = significant.sum().item()\n",
    "    plt.title(\n",
    "        f'DistShield on BERT MRPC', fontsize=20\n",
    "    )\n",
    "    \n",
    "    plt.xlabel('Weight Value', fontsize=20)\n",
    "    plt.ylabel('Frequency', fontsize=20)\n",
    "    plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{abs(x):.0f}'))\n",
    "    plt.legend(loc='upper right', fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.savefig('./bert_mrpc.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    # plt.show()"
   ],
   "id": "a42ce02c37196a42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot_weight_comparison_gpu(model, ori_dict, 'bert.encoder.layer.6.attention.self.query.weight')\n",
    "plot_combined_weights_gpu(model, ori_dict)"
   ],
   "id": "400351607eab7928",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
