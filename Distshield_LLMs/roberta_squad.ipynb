{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('deepset/roberta-base-squad2')\n",
    "model = AutoModelForQuestionAnswering.from_pretrained('deepset/roberta-base-squad2')\n",
    "model_ori = AutoModelForQuestionAnswering.from_pretrained('deepset/roberta-base-squad2')\n",
    "\n",
    "dataset = load_dataset('rajpurkar/squad')"
   ],
   "id": "494583e3f4bffbba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def draw(weights, name, mask):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bin_width = 0.005\n",
    "    bins = np.arange(-0.6, 0.6, bin_width)\n",
    "    plt.hist(weights.view(-1).cpu(), bins=bins, alpha=0.75, color='blue', edgecolor='black')\n",
    "    plt.hist(weights[mask[name + '.weight'] > 0].view(-1).cpu(), bins=bins, alpha=0.75, color='red', edgecolor='black')\n",
    "    plt.title(name)\n",
    "    plt.xlim([-0.6, 0.6])\n",
    "    plt.ylim([0, 300])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    # plt.savefig(f\"imgs/{name}.png\")\n",
    "    # plt.close()\n",
    "    return"
   ],
   "id": "87afe6e0f93a278f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(model)\n",
    "print(dataset)\n",
    "# print(dataset['train']['sentence1'][0])\n",
    "# print(dataset['train']['sentence2'][0])\n",
    "# print(dataset['train']['label'][0])"
   ],
   "id": "257b07da8a69d84d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def prepare_train_features(examples):\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples['question'],\n",
    "        examples['context'],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        stride=128,  \n",
    "        padding='max_length',\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "    \n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "    \n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        \n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples['answers'][sample_index]\n",
    "        \n",
    "        if len(answers['answer_start']) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(0)\n",
    "            tokenized_examples[\"end_positions\"].append(0)\n",
    "            continue\n",
    "            \n",
    "        start_char = answers['answer_start'][0]\n",
    "        end_char = start_char + len(answers['text'][0])\n",
    "        \n",
    "        token_start_index = 0\n",
    "        while sequence_ids[token_start_index] != 1:  \n",
    "            token_start_index += 1\n",
    "            \n",
    "        token_end_index = len(input_ids) - 1\n",
    "        while sequence_ids[token_end_index] != 1:  \n",
    "            token_end_index -= 1\n",
    "            \n",
    "        if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "            tokenized_examples[\"start_positions\"].append(0)\n",
    "            tokenized_examples[\"end_positions\"].append(0)\n",
    "        else:\n",
    "            while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                token_start_index += 1\n",
    "            tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "            \n",
    "            while offsets[token_end_index][1] >= end_char:\n",
    "                token_end_index -= 1\n",
    "            tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "    \n",
    "    return tokenized_examples\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    prepare_train_features,\n",
    "    batched=True,\n",
    "    remove_columns=dataset['train'].column_names\n",
    ")\n",
    "\n",
    "tokenized_dataset.set_format('pt', columns=[\n",
    "    'input_ids', \n",
    "    'attention_mask', \n",
    "    'start_positions', \n",
    "    'end_positions'\n",
    "])\n",
    "\n",
    "print(tokenized_dataset)\n",
    "print(\"\\n示例数据:\")\n",
    "print(\"Input IDs:\", tokenized_dataset['train']['input_ids'][0])\n",
    "print(\"Start Position:\", tokenized_dataset['train']['start_positions'][0])\n",
    "print(\"End Position:\", tokenized_dataset['train']['end_positions'][0])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset['train'], \n",
    "    batch_size=8, \n",
    "    shuffle=True\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_dataset['validation'], \n",
    "    batch_size=8, \n",
    "    shuffle=False\n",
    ")\n",
    "my_dataloader = DataLoader(\n",
    "    tokenized_dataset['validation'].select(range(400)), \n",
    "    batch_size=8, \n",
    "    shuffle=False\n",
    ")"
   ],
   "id": "9558143d56beaed1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(dataset)",
   "id": "cc6abd1c75eb2cd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print(tokenized_dataset)\n",
    "# print(tokenized_dataset['train']['labels'][0])\n",
    "# print(tokenized_dataset['train']['input_ids'][0])\n",
    "# print(tokenized_dataset['train']['token_type_ids'][0])\n",
    "# print(tokenized_dataset['train']['attention_mask'][0])"
   ],
   "id": "91c76df23bdd20f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bc3e44f1874021b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# train_dataloader = DataLoader(tokenized_dataset['train'], batch_size=1, shuffle=False)\n",
    "# eval_dataloader = DataLoader(tokenized_dataset['validation'], batch_size=1, shuffle=False)\n",
    "device = 'cuda'\n",
    "\n",
    "model_ori = model_ori.to(device)\n",
    "model_ori.train()\n",
    "model_ori.zero_grad()\n",
    "\n",
    "for data in train_dataloader:\n",
    "    #print(data)\n",
    "    data = {k: v.to(device) for k, v in data.items()}\n",
    "    outputs = model_ori(**data)\n",
    "    print(model_ori.roberta.encoder.layer[-1].attention.self.query.weight.grad)\n",
    "    print(outputs.loss)\n",
    "    outputs.loss.backward()\n",
    "    print(model_ori.roberta.encoder.layer[-1].attention.self.query.weight.grad)\n",
    "    print(torch.argmax(outputs.start_logits, dim=1))\n",
    "    print(torch.argmax(outputs.end_logits, dim=1))\n",
    "    print(data['start_positions'])\n",
    "    print(data['end_positions'])\n",
    "    # print(torch.argmax(outputs.logits.flatten())==data['labels'][0])\n",
    "\n",
    "    break\n",
    "    "
   ],
   "id": "a6d32e672b1212e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ori_dict = {}\n",
    "ori_max = {}\n",
    "ori_min = {}\n",
    "for name, module in model_ori.named_modules():\n",
    "    if 'query' in name or 'key' in name or 'value' in name:\n",
    "        name = name + '.weight'\n",
    "        ori_dict[name] = module.weight\n",
    "        flattened_para = module.weight.view(-1)\n",
    "        sorted_tensor, _ = torch.sort(flattened_para)\n",
    "        num_elements = flattened_para.numel()\n",
    "        top_1_percent_idx = num_elements - 50\n",
    "        bottom_1_percent_idx = 50\n",
    "        top_1_percent_value = sorted_tensor[top_1_percent_idx].item()\n",
    "        bottom_1_percent_value = sorted_tensor[bottom_1_percent_idx].item()\n",
    "        ori_max[name] = top_1_percent_value\n",
    "        ori_min[name] = bottom_1_percent_value"
   ],
   "id": "dfc2b0b84966bbf9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "question_answerer = pipeline('question-answering', model=model, tokenizer=tokenizer, device='cuda')\n",
    "\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for i in tqdm(range(10570)):\n",
    "#         result = question_answerer(question=dataset['validation'][i]['question'], context=dataset['validation'][i]['context'])\n",
    "#         for answer in dataset['validation'][i]['answers']['text']:\n",
    "#             if answer == result['answer']:\n",
    "#                 correct += 1\n",
    "#                 break\n",
    "#         total += 1\n",
    "# print(\"accuracy:\", correct / total)"
   ],
   "id": "1807cd59fa59a9e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Device set to use cuda\n",
    "\n",
    "100%|██████████| 10570/10570 [01:15<00:00, 140.87it/s]\n",
    "\n",
    "accuracy: 0.819678334910123"
   ],
   "id": "9f9b41cd16f88144"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for name, module in model.named_modules():\n",
    "#     if 'query' in name or 'key' in name or 'value' in name:\n",
    "#         print(name)\n",
    "#         print(module.weight.numel())\n",
    "mask = {}\n",
    "idx_list = []\n",
    "ori_w = []\n",
    "ratio = 0.001\n",
    "for name, module in model_ori.named_modules():\n",
    "    if 'query' in name or 'key' in name or 'value' in name:\n",
    "        weight_name = name + '.weight'\n",
    "        weights = module.weight.data\n",
    "        \n",
    "        flattened_weights = weights.view(-1)\n",
    "        replace_count = int(ratio * len(flattened_weights))\n",
    "        replace_count = max(0, replace_count)\n",
    "        print(replace_count)\n",
    "        mask[weight_name] = torch.zeros_like(flattened_weights)\n",
    "        \n",
    "        if module.weight.grad is None:\n",
    "            raise ValueError(f\"{name}\")\n",
    "        grad_abs = module.weight.grad.detach().abs()\n",
    "        _, topk_idx = grad_abs.view(-1).topk(replace_count)\n",
    "        mask[weight_name][topk_idx] = 1\n",
    "        \n",
    "        mask[weight_name] = mask[weight_name].view(weights.size())\n",
    "        \n",
    "        indexes = torch.nonzero(mask[weight_name], as_tuple=True)\n",
    "        idx_list.append(indexes)\n",
    "        selected_weights = weights[indexes]\n",
    "        ori_w.extend(selected_weights.cpu().detach().numpy().flatten())\n",
    "\n",
    "print(\"mask include:\", mask.keys())"
   ],
   "id": "87c2ebba6e6256d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "optimizer = AdamW(model.parameters(), lr=0.0005, eps=1e-8)\n",
    "\n",
    "for epoch in range(10):  # Specify how many epochs to cycle through the training\n",
    "    # set to the eval mode to fix the paramaters of batchnorm\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    progress_bar = tqdm(my_dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        kld = 0\n",
    "        cnt = 0\n",
    "        total_cnt = 0\n",
    "        for name, para in model.named_parameters():\n",
    "            if name in mask:\n",
    "                flattened_para = para[mask[name] > 0].view(-1)\n",
    "                flattened_ori = ori_dict[name][mask[name] > 0].view(-1)\n",
    "                flattened_para = flattened_para[torch.argsort(flattened_para)]\n",
    "                flattened_ori = flattened_ori[torch.argsort(flattened_ori)]\n",
    "                cnt += 1\n",
    "                if flattened_para.numel() != 0:\n",
    "                    kl_t1 = torch.log_softmax(flattened_para, dim=0)\n",
    "                    kl_t2 = torch.softmax(flattened_ori, dim=0)\n",
    "                    kld_tmp = torch.nn.functional.kl_div(kl_t1, kl_t2, reduction='sum')\n",
    "                    if kld_tmp.item() > 0.0:\n",
    "                        kld += kld_tmp\n",
    "        loss_new = -loss + 2 ** (kld * 1e3)\n",
    "        total_loss += loss_new.item()\n",
    "        \n",
    "\n",
    "        loss_new.backward()\n",
    "        for name, para in model.named_parameters():\n",
    "            if name in mask:\n",
    "                para.grad *= mask[name].long()\n",
    "            else:\n",
    "                para.grad *= 0\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            for name, para in model.named_parameters():\n",
    "                if name in mask:\n",
    "                    # param.clamp_(-arg.clip, arg.clip)\n",
    "                    para.data = (1 - mask[name]) * para + (mask[name] * para).clamp_(ori_min[name] * 0.85,\n",
    "                                                                                         ori_max[name] * 0.75)\n",
    "\n",
    "        progress_bar.set_postfix({'loss': loss.item(),'loss_new': loss_new.item(),'kld': 2 ** (kld.item() * 1e3)})\n",
    "    \n",
    "    # correct = 0\n",
    "    # total = 0\n",
    "    # with torch.no_grad():\n",
    "    #     for i in tqdm(range(10570)):\n",
    "    #         result = question_answerer(question=dataset['validation'][i]['question'], context=dataset['validation'][i]['context'])\n",
    "    #         for answer in dataset['validation'][i]['answers']['text']:\n",
    "    #             if answer == result['answer']:\n",
    "    #                 correct += 1\n",
    "    #                 break\n",
    "    #         total += 1\n",
    "    # accuracy = correct / total\n",
    "    # print(\"accuracy:\", accuracy)\n",
    "    # \n",
    "    # if accuracy > 0.7:\n",
    "    #     continue\n",
    "    changed = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if (name + '.weight') in mask:\n",
    "            changed += (mask[name + '.weight'] > 0).sum()\n",
    "        if 'value' in name:\n",
    "            if 'layer.6' in name:\n",
    "                draw(module.weight.data, name, mask)\n",
    "                # draw(ori_dict[name + '.weight'].data, name, mask)\n",
    "                name = name + '.weight'\n",
    "                flattened_weights = module.weight.data.cpu().numpy().flatten()\n",
    "                flattened_ori = ori_dict[name].data.cpu().numpy().flatten()\n",
    "                weight_diff = flattened_weights - flattened_ori\n",
    "                changed_indices = np.where(np.abs(weight_diff) > 1e-5)\n",
    "                print(len(changed_indices[0]))\n",
    "    # \n",
    "    print(f'{changed} weights changed')\n",
    "    if changed < 8500:\n",
    "        break\n",
    "    # if accuracy > 0.01:\n",
    "    #     continue\n",
    "    step = 0.1\n",
    "    with torch.no_grad():\n",
    "        for name, module in model.named_modules():\n",
    "            name = name + '.weight'\n",
    "            if 'query' in name or 'key' in name or 'value' in name:\n",
    "                weights = module.weight.data\n",
    "                # flattened_weights = weights.view(-1)\n",
    "                replace_count = int(step * mask[name].sum())\n",
    "                # print((module.weight.grad.detach().abs() * mask[name]).view(-1).shape)\n",
    "                if replace_count == 0:\n",
    "                    replace_count = 1\n",
    "                temp_weight = module.weight.grad.detach().abs() * mask[name]\n",
    "                temp_weight += 1 - mask[name]\n",
    "                temp_weight = temp_weight.view(-1)\n",
    "                _, w_idx_mink = temp_weight.topk(replace_count, largest=False)\n",
    "                zero_mask = torch.zeros_like(temp_weight)\n",
    "                zero_mask[w_idx_mink] = 1\n",
    "                # if 'layer2.1.conv1' in name or 'features.4' in name:\n",
    "                #     print((weights[mask[name] > 0]).numel())\n",
    "                #     print((weights.view(-1) != ori_dict[name].view(-1)).sum().item())\n",
    "                    # print(weights[mask[name] > 0])\n",
    "                    # print(ori_dict[name][mask[name] > 0])\n",
    "                    # mask_temp = mask[name].clone()\n",
    "                mask[name][zero_mask.view(mask[name].size()) > 0] = 0\n",
    "                weights[zero_mask.view(mask[name].size()) > 0] = ori_dict[name][zero_mask.view(mask[name].size()) > 0]\n",
    "                # if 'layer2.1.conv1' in name:\n",
    "                    # print(weights[mask_temp > 0])\n",
    "                    # print(ori_dict[name][mask_temp > 0])\n",
    "                    # print((weights[mask[name] > 0]).numel())\n",
    "                    # print((weights.view(-1) != ori_dict[name].view(-1)).sum().item())\n",
    "    optimizer = AdamW(model.parameters(), lr=0.0005, eps=1e-8)\n"
   ],
   "id": "290cd5df51ec1a5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for i in tqdm(range(10570)):\n",
    "#         result = question_answerer(question=dataset['validation'][i]['question'], context=dataset['validation'][i]['context'])\n",
    "#         for answer in dataset['validation'][i]['answers']['text']:\n",
    "#             if answer == result['answer']:\n",
    "#                 correct += 1\n",
    "#                 break\n",
    "#         total += 1\n",
    "# print(\"accuracy:\", correct / total)"
   ],
   "id": "df61f81a4fbd84ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for name, module in model.named_modules():\n",
    "#     if 'query' in name or 'key' in name or 'value' in name:\n",
    "#         if 'layer.7' in name:\n",
    "#             draw(module.weight.data, name, mask)"
   ],
   "id": "9a7e3da2e1f25416",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for name, module in model.named_modules():\n",
    "    if 'query' in name or 'key' in name or 'value' in name:\n",
    "        if 'layer.0' in name:\n",
    "            draw(module.weight.data, name, mask)\n",
    "            # draw(ori_dict[name + '.weight'].data, name, mask)\n",
    "            name = name + '.weight'\n",
    "            flattened_weights = module.weight.data.cpu().numpy().flatten()\n",
    "            flattened_ori = ori_dict[name].data.cpu().numpy().flatten()\n",
    "            weight_diff = flattened_weights - flattened_ori\n",
    "            changed_indices = np.where(np.abs(weight_diff) > 1e-5)\n",
    "            print(len(changed_indices[0]))\n",
    "            print(ori_max[name])\n",
    "            print(ori_min[name])"
   ],
   "id": "4d12c5a757b7df5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f'paras :{sum(p.numel() for p in model_ori.parameters())}')",
   "id": "dc372430052fd306",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "progress_bar = tqdm(range(10570))\n",
    "with torch.no_grad():\n",
    "    for i in progress_bar:\n",
    "        result = question_answerer(question=dataset['validation'][i]['question'], context=dataset['validation'][i]['context'])\n",
    "        for answer in dataset['validation'][i]['answers']['text']:\n",
    "            if answer == result['answer']:\n",
    "                correct += 1\n",
    "                break\n",
    "        total += 1\n",
    "        accuracy = correct / total\n",
    "        progress_bar.set_postfix({'acc': accuracy})\n",
    "print(\"accuracy:\", accuracy)"
   ],
   "id": "5b192bd53b818d80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "attacker_dataloader = DataLoader(\n",
    "    tokenized_dataset['validation'].select(range(500)), \n",
    "    batch_size=8, \n",
    "    shuffle=False\n",
    ")\n",
    "model.train()\n",
    "model.zero_grad()\n",
    "\n",
    "for data in attacker_dataloader:\n",
    "    #print(data)\n",
    "    data = {k: v.to(device) for k, v in data.items()}\n",
    "    outputs = model(**data)\n",
    "    outputs.loss.backward()\n",
    "    break\n",
    "    \n",
    "def get_gradients(model, dataloader):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for data in dataloader:\n",
    "        #print(data)\n",
    "        data = {k: v.to(device) for k, v in data.items()}\n",
    "        outputs = model(**data)\n",
    "        outputs.loss.backward()\n",
    "        break\n",
    "    gradients = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'query' in name or 'key' in name or 'value' in name:\n",
    "            gradients[name] = param.grad.abs().clone()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    return gradients\n",
    "\n",
    "\n",
    "gradients = get_gradients(model, attacker_dataloader)\n",
    "masks = {}\n",
    "for name, grad in gradients.items():\n",
    "    threshold = torch.quantile(grad, 0.95)\n",
    "    mask = (grad >= threshold).float()\n",
    "    masks[name] = mask\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if 'query' in name or 'key' in name or 'value' in name:\n",
    "        mask = masks[name].to(device)\n",
    "\n",
    "\n",
    "        def make_hook(m):\n",
    "            def hook(grad):\n",
    "                return grad * m\n",
    "\n",
    "            return hook\n",
    "\n",
    "\n",
    "        param.requires_grad = True\n",
    "        param.register_hook(make_hook(mask))\n"
   ],
   "id": "a0e0d75fc3c53ebe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.003, eps=1e-8)\n",
    "\n"
   ],
   "id": "f485098f8e1833b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for epoch in range(5):  # Specify how many epochs to cycle through the training\n",
    "    # set to the eval mode to fix the paramaters of batchnorm\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    progress_bar = tqdm(attacker_dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    progress_bar = tqdm(range(100))\n",
    "    with torch.no_grad():\n",
    "        for i in progress_bar:\n",
    "            result = question_answerer(question=dataset['validation'][i]['question'], context=dataset['validation'][i]['context'])\n",
    "            for answer in dataset['validation'][i]['answers']['text']:\n",
    "                if answer == result['answer']:\n",
    "                    correct += 1\n",
    "                    break\n",
    "            total += 1\n",
    "            accuracy = correct / total\n",
    "            progress_bar.set_postfix({'acc': accuracy})\n",
    "    print(\"accuracy:\", accuracy)\n",
    "    "
   ],
   "id": "45e2935a94461d94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "    correct = 0\n",
    "    total = 0\n",
    "    progress_bar = tqdm(range(10570))\n",
    "    with torch.no_grad():\n",
    "        for i in progress_bar:\n",
    "            result = question_answerer(question=dataset['validation'][i]['question'], context=dataset['validation'][i]['context'])\n",
    "            for answer in dataset['validation'][i]['answers']['text']:\n",
    "                if answer == result['answer']:\n",
    "                    correct += 1\n",
    "                    break\n",
    "            total += 1\n",
    "            accuracy = correct / total\n",
    "            progress_bar.set_postfix({'acc': accuracy})\n",
    "    print(\"accuracy:\", accuracy)"
   ],
   "id": "859099beb4db6500",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "def plot_weight_comparison_gpu(model, ori_dict, name):\n",
    "    device = next(model.parameters()).device\n",
    "    weights_post = model.state_dict()[name].detach()\n",
    "    weights_pre = ori_dict[name].detach().to(device)\n",
    "    \n",
    "    def gpu_hist(tensor, bins):\n",
    "        counts = torch.histc(tensor, bins=len(bins)-1, min=bins[0], max=bins[-1])\n",
    "        return counts.cpu().numpy(), bins\n",
    "    \n",
    "    bin_edges_gpu = torch.linspace(-0.3, 0.3, steps=121, device=device)\n",
    "    bin_edges = bin_edges_gpu.cpu().numpy()\n",
    "    bin_width = bin_edges[1] - bin_edges[0]\n",
    "    \n",
    "    pre_freq, _ = gpu_hist(weights_pre, bin_edges_gpu)\n",
    "    post_freq, _ = gpu_hist(weights_post, bin_edges_gpu)\n",
    "    \n",
    "    lim = max(int(max(pre_freq.max(), post_freq.max()) * 1.2), 100)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.bar(bin_edges[:-1], pre_freq, width=bin_width, align='edge',\n",
    "            alpha=0.5, color='royalblue', edgecolor='none', label='Original Weights')\n",
    "    \n",
    "    plt.bar(bin_edges[:-1], -post_freq, width=bin_width, align='edge',\n",
    "            alpha=0.5, color='coral', edgecolor='none', label='Current Weights')\n",
    "    \n",
    "    diff = torch.abs(weights_post - weights_pre)\n",
    "    significant = diff > 1e-10  \n",
    "    if significant.any():\n",
    "        sig_pre = weights_pre[significant]\n",
    "        sig_post = weights_post[significant]\n",
    "        sig_pre_freq, _ = gpu_hist(sig_pre, bin_edges_gpu)\n",
    "        sig_post_freq, _ = gpu_hist(sig_post, bin_edges_gpu)\n",
    "        \n",
    "        plt.bar(bin_edges[:-1], sig_pre_freq, width=bin_width, align='edge',\n",
    "                alpha=0.8, color='blue', edgecolor='none', label='Significant Change (Orig)')\n",
    "        plt.bar(bin_edges[:-1], -sig_post_freq, width=bin_width, align='edge',\n",
    "                alpha=0.8, color='red', edgecolor='none', label='Significant Change (Current)')\n",
    "    \n",
    "    plt.xlim(-0.3, 0.3)\n",
    "    lim = 20\n",
    "    plt.ylim(-lim, lim)\n",
    "    plt.grid(True, which='both', linestyle=':', alpha=0.5)\n",
    "    plt.axhline(0, color='k', linewidth=1)\n",
    "    plt.title(f'Weight Distribution Comparison: {name}', fontsize=14)\n",
    "    plt.xlabel('Weight Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{abs(x):.0f}'))\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_combined_weights_gpu(model, ori_dict):\n",
    "    weight_range = 0.7\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    all_weights_pre = torch.tensor([], device=device)\n",
    "    all_weights_post = torch.tensor([], device=device)\n",
    "    all_diffs = torch.tensor([], device=device)\n",
    "    \n",
    "    for name, param in model.state_dict().items():\n",
    "        if ('query' in name or 'key' in name or 'value' in name) and 'weight' in name:\n",
    "            weights_post = param.detach().flatten()\n",
    "            weights_pre = ori_dict[name].detach().to(device).flatten()\n",
    "            diff = torch.abs(weights_post - weights_pre)\n",
    "            \n",
    "            all_weights_pre = torch.cat([all_weights_pre, weights_pre])\n",
    "            all_weights_post = torch.cat([all_weights_post, weights_post])\n",
    "            all_diffs = torch.cat([all_diffs, diff])\n",
    "    \n",
    "    bin_edges_gpu = torch.linspace(-weight_range, weight_range, steps=121, device=device)\n",
    "    \n",
    "    def gpu_hist(tensor):\n",
    "        return torch.histc(tensor, bins=120, min=-weight_range, max=weight_range).cpu().numpy()\n",
    "    \n",
    "    pre_freq = gpu_hist(all_weights_pre)\n",
    "    post_freq = gpu_hist(all_weights_post)\n",
    "    \n",
    "    diff = torch.abs(all_weights_post - all_weights_pre)\n",
    "    significant = diff > 1e-10\n",
    "    sig_pre_freq = gpu_hist(all_weights_pre[significant])\n",
    "    sig_post_freq = gpu_hist(all_weights_post[significant])\n",
    "    \n",
    "    bin_edges = bin_edges_gpu.cpu().numpy()\n",
    "    bin_width = bin_edges[1] - bin_edges[0]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.bar(bin_edges[:-1], pre_freq, width=bin_width, align='edge',\n",
    "            alpha=0.3, color='lightblue', edgecolor='black', \n",
    "            label='Baseline')\n",
    "    plt.bar(bin_edges[:-1], -post_freq, width=bin_width, align='edge',\n",
    "            alpha=0.2, color='red', edgecolor='black',\n",
    "            label='DistShield')\n",
    "    \n",
    "    plt.bar(bin_edges[:-1], sig_pre_freq, width=bin_width, align='edge',\n",
    "            alpha=0.6, color='blue', edgecolor='black',\n",
    "            label='Before')\n",
    "    plt.bar(bin_edges[:-1], -sig_post_freq, width=bin_width, align='edge',\n",
    "            alpha=0.6, color='red', edgecolor='black',\n",
    "            label='After')\n",
    "    \n",
    "    max_freq = max(pre_freq.max(), post_freq.max())\n",
    "    plt.xlim(-weight_range, weight_range)\n",
    "    lim = 2500\n",
    "    plt.ylim(-lim, lim)\n",
    "    plt.grid(True, which='both', linestyle=':', alpha=0.5)\n",
    "    plt.axhline(0, color='k', linewidth=1)\n",
    "    \n",
    "    total_params = len(all_weights_pre)\n",
    "    changed_params = significant.sum().item()\n",
    "    plt.title(\n",
    "        f'DistShield on RoBERTa SQuAD', fontsize=20\n",
    "    )\n",
    "    \n",
    "    plt.xlabel('Weight Value', fontsize=20)\n",
    "    plt.ylabel('Frequency', fontsize=20)\n",
    "    plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{abs(x):.0f}'))\n",
    "    plt.legend(loc='upper right', fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.savefig('./roberta_squad.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    # plt.show()"
   ],
   "id": "e5b844795e7e059",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_combined_weights_gpu(model, ori_dict)",
   "id": "3990955876e4dd78",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
